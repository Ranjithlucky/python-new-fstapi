rom langchain_google_vertexai import VertexAIEmbeddings
from google.cloud import aiplatform
import vertexai
from vertexai.preview.generative_models import GenerativeModel
 
# **SETUP CONFIGURATION**
project = "cog01jht4hs5k3285da80mtejnh8g"  # Ensure this is a valid project ID
location = "us-central1"  # Fixed typo in location
index_name = "INDEX_EP_ID"  # Ensure this is the correct index endpoint ID
 
# **INITIALIZE GOOGLE CLOUD SERVICES**
aiplatform.init(project=project, location=location)
vertexai.init(project=project, location=location)
 
# Index details (ensure these are correct)
Index_name = "test-tririga-index"
Index_id = "7476885777062821888"
Index_endpoint_id = "7120432903430864896"
Index_endpoint_name = "test-tririga-index-endpoint"
 
# **LOAD MODELS**
model = GenerativeModel(model="gemini-pro")
 
# **LOAD MATCHING ENGINE INDEX ENDPOINT**
lakeside_index_ep = aiplatform.MatchingEngineIndexEndpoint(index_endpoint_name=index_name)
 
# **HELPER FUNCTION: GET EMBEDDINGS**
def get_embedded_data(data):
    embeddings = VertexAIEmbeddings(model="text-embedding-005")
    return embeddings.embed_documents(data)
 
# **PERFORM SEMANTIC SEARCH**
query = ["Ask related to the document:"]
qry_emb = get_embedded_data(query)
 
# **FIND NEAREST NEIGHBORS**
response = lakeside_index_ep.find_neighbors(
    deployed_index_id=index_name,  # Ensure this is the correct deployed index ID
    queries=[qry_emb[0]],
    num_neighbors=10,
)
 
# **EXTRACT MATCHING IDS**
matching_ids = [neighbor.id for sublist in response for neighbor in sublist]
 
# **GENERATE CONTEXT FUNCTION (Placeholder)**
def generate_context(matching_ids):
    return f"Retrieved documents for IDs: {matching_ids}"
 
# **RETRIEVE CONTEXT**
context = generate_context(matching_ids)
print(context)
